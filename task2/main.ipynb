{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA93WUy1zzWf"
      },
      "source": [
        "## Import stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "-ZMgCvSRFqxE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "tensorflow doesn't detects GPU: \n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 17265062595943054103\n",
            "]\n",
            "\n",
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "torch detects GPU:  True\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import logging\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "import torch \n",
        "import torch.jit\n",
        "import torch.nn as nn \n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "import sklearn.metrics as metrics\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "print(\"tensorflow doesn't detects GPU: \")\n",
        "print(device_lib.list_local_devices() )\n",
        "print(tf.test.gpu_device_name())\n",
        "print(tf.config.list_physical_devices())\n",
        "\n",
        "print(\"torch detects GPU: \" , torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_score(df_true, df_submission):\n",
        "    for i in range(df_true.shape[1]):\n",
        "        print(\"score for col \",i,\": \" , metrics.roc_auc_score(df_true[:,i], df_submission[:,i]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC3EQFi20buB"
      },
      "source": [
        "## Load training data from csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_orig shape:  (18995, 420)\n",
            "X_normalized shape:  (18995, 420)\n",
            "Y1 shape:  (18995, 10)\n",
            "Y2 shape:  (18995,)\n",
            "Y3 shape:  (18995, 4)\n"
          ]
        }
      ],
      "source": [
        "features_df_orig = pd.read_csv(\"train_features_fixed.csv\")\n",
        "features_df_normalized = pd.read_csv(\"train_features_normalized.csv\")\n",
        "labels_df = pd.read_csv(\"train_labels.csv\")\n",
        "\n",
        "\n",
        "# load all columns except the first two\n",
        "X_orig = np.array(features_df_orig.iloc[:, 2:].values,  dtype=float)\n",
        "X_orig = X_orig.reshape(227940//12,35*12)\n",
        "X_normalized = np.array(features_df_normalized.iloc[:, 2:].values,  dtype=float)\n",
        "X_normalized = X_normalized.reshape(227940//12,35*12)\n",
        "\n",
        "\n",
        "#use train to validation ratio of 0.8\n",
        "X_orig_train = X_orig[:int(X_orig.shape[0]*0.8)]\n",
        "X_orig_valid = X_orig[int(X_orig.shape[0]*0.8):]\n",
        "X_normalized_train = X_normalized[:int(X_normalized.shape[0]*0.8)]\n",
        "X_normalized_valid = X_normalized[int(X_normalized.shape[0]*0.8):]\n",
        "\n",
        "Y1 = np.array(labels_df.iloc[:, 1:11].values,  dtype=float)\n",
        "Y1_train = Y1[:int(Y1.shape[0]*0.8)]\n",
        "Y1_valid = Y1[int(Y1.shape[0]*0.8):]\n",
        "\n",
        "Y2 = np.array(labels_df.iloc[:, 11].values,  dtype=float)\n",
        "Y2_train = Y2[:int(Y2.shape[0]*0.8)]\n",
        "Y2_valid = Y2[int(Y2.shape[0]*0.8):]\n",
        "\n",
        "Y3 = np.array(labels_df.iloc[:, 12:].values,  dtype=float)\n",
        "Y3_train = Y3[:int(Y3.shape[0]*0.8)]\n",
        "Y3_valid = Y3[int(Y3.shape[0]*0.8):]\n",
        "\n",
        "print(\"X_orig shape: \", X_orig.shape)\n",
        "print(\"X_normalized shape: \", X_normalized.shape)\n",
        "print(\"Y1 shape: \", Y1.shape)\n",
        "print(\"Y2 shape: \", Y2.shape)\n",
        "print(\"Y3 shape: \", Y3.shape)\n",
        "\n",
        "\n",
        "\n",
        "# print(inputs_dim)\n",
        "# print(outputs_dim)\n",
        "\n",
        "# X = tf.cast(X, tf.float32)\n",
        "# Y = tf.cast(Y, tf.float32)\n",
        "\n",
        "#print(X.shape)\n",
        "# random.shuffle(image_ids)\n",
        "# random.shuffle(diagnostics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM7_9Klvq7MO"
      },
      "source": [
        "## TASK 1: ORDERING OF MEDICAL TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "pRllo2HLfXiu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "475/475 [==============================] - 0s 873us/step - loss: 0.1523 - mean_squared_error: 0.1523\n",
            "Epoch 2/10\n",
            "475/475 [==============================] - 0s 830us/step - loss: 0.1440 - mean_squared_error: 0.1440\n",
            "Epoch 3/10\n",
            "475/475 [==============================] - 0s 700us/step - loss: 0.1444 - mean_squared_error: 0.1444\n",
            "Epoch 4/10\n",
            "475/475 [==============================] - 0s 692us/step - loss: 0.1450 - mean_squared_error: 0.1450\n",
            "Epoch 5/10\n",
            "475/475 [==============================] - 0s 679us/step - loss: 0.1447 - mean_squared_error: 0.1447\n",
            "Epoch 6/10\n",
            "475/475 [==============================] - 0s 676us/step - loss: 0.1457 - mean_squared_error: 0.1457\n",
            "Epoch 7/10\n",
            "475/475 [==============================] - 0s 688us/step - loss: 0.1467 - mean_squared_error: 0.1467\n",
            "Epoch 8/10\n",
            "475/475 [==============================] - 0s 691us/step - loss: 0.1454 - mean_squared_error: 0.1454\n",
            "Epoch 9/10\n",
            "475/475 [==============================] - 0s 697us/step - loss: 0.1468 - mean_squared_error: 0.1468\n",
            "Epoch 10/10\n",
            "475/475 [==============================] - 0s 693us/step - loss: 0.1461 - mean_squared_error: 0.1461\n",
            "Finished training the model\n"
          ]
        }
      ],
      "source": [
        "inputs_dim = X_normalized.shape[1]\n",
        "outputs_dim = Y1.shape[1]\n",
        "\n",
        "model1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(units=100, input_shape=[inputs_dim], activation='sigmoid'),\n",
        "  tf.keras.layers.Dense(units=25, activation='sigmoid'),\n",
        "  tf.keras.layers.Dense(units=outputs_dim)\n",
        "])\n",
        "\n",
        "model1.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1), metrics=['mean_squared_error'])\n",
        "\n",
        "history = model1.fit(X_normalized_train, Y1_train, epochs=10) # , verbose=False\n",
        "print(\"Finished training the model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TASK 1: EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score for col  0 :  0.5069146988517818\n",
            "score for col  1 :  0.5109629561746497\n",
            "score for col  2 :  0.5\n",
            "score for col  3 :  0.5\n",
            "score for col  4 :  0.49412719886617706\n",
            "score for col  5 :  0.5\n",
            "score for col  6 :  0.5\n",
            "score for col  7 :  0.5\n",
            "score for col  8 :  0.5103490053144917\n",
            "score for col  9 :  0.49727675400404475\n"
          ]
        }
      ],
      "source": [
        "pred = model1.predict(X_normalized_valid)\n",
        "for i in range(Y1_valid.shape[1]):\n",
        "    print(\"score for col \",i,\": \" , metrics.roc_auc_score(Y1_valid[:,i], pred[:,i]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TASK 2: SEPSIS PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "475/475 [==============================] - 0s 681us/step - loss: 19.5741 - mean_squared_error: 19.5741\n",
            "Epoch 2/5\n",
            "475/475 [==============================] - 0s 645us/step - loss: 0.0630 - mean_squared_error: 0.0630\n",
            "Epoch 3/5\n",
            "475/475 [==============================] - 0s 699us/step - loss: 0.0560 - mean_squared_error: 0.05600s - loss: 0.0570 - mean_squared_err\n",
            "Epoch 4/5\n",
            "475/475 [==============================] - 0s 702us/step - loss: 0.0550 - mean_squared_error: 0.0550\n",
            "Epoch 5/5\n",
            "475/475 [==============================] - 0s 750us/step - loss: 0.0550 - mean_squared_error: 0.0550\n",
            "Finished training the model\n"
          ]
        }
      ],
      "source": [
        "inputs_dim = X_normalized.shape[1]\n",
        "outputs_dim = 1\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(units=100, input_shape=[inputs_dim], activation='relu'),\n",
        "  tf.keras.layers.Dense(units=25, activation='relu'),\n",
        "  tf.keras.layers.Dense(units=outputs_dim)\n",
        "])\n",
        "\n",
        "model2.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1), metrics=['mean_squared_error'])\n",
        "\n",
        "history = model2.fit(X_normalized_train, Y2_train, epochs=5) # , verbose=False\n",
        "print(\"Finished training the model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TASK 2: EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score :  0.5\n"
          ]
        }
      ],
      "source": [
        "pred = model2.predict(X_normalized_valid)\n",
        "print(\"score : \" , metrics.roc_auc_score(Y1_valid, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TASK 3: KEYS VITALS SIGNS PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "475/475 [==============================] - 0s 657us/step - loss: 217983.8594 - mean_squared_error: 217983.8594\n",
            "Epoch 2/5\n",
            "475/475 [==============================] - 0s 661us/step - loss: 126.5711 - mean_squared_error: 126.5711\n",
            "Epoch 3/5\n",
            "475/475 [==============================] - 0s 664us/step - loss: 102.7951 - mean_squared_error: 102.7951\n",
            "Epoch 4/5\n",
            "475/475 [==============================] - 0s 676us/step - loss: 132.3274 - mean_squared_error: 132.3274\n",
            "Epoch 5/5\n",
            "475/475 [==============================] - 0s 655us/step - loss: 106.8408 - mean_squared_error: 106.8408\n",
            "Finished training the model\n"
          ]
        }
      ],
      "source": [
        "inputs_dim = X_orig.shape[1]\n",
        "outputs_dim = Y3.shape[1]\n",
        "\n",
        "model3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(units=100, input_shape=[inputs_dim], activation='relu'),\n",
        "  tf.keras.layers.Dense(units=25, activation='relu'),\n",
        "  tf.keras.layers.Dense(units=outputs_dim)\n",
        "])\n",
        "\n",
        "model3.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1), metrics=['mean_squared_error'])\n",
        "\n",
        "history = model3.fit(X_orig_train, Y3_train, epochs=5) # , verbose=False\n",
        "print(\"Finished training the model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TASK 3: EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score for col  0 :  0.9781298142088239\n",
            "score for col  1 :  0.9921901556178777\n",
            "score for col  2 :  0.9255223387803362\n",
            "score for col  3 :  0.8847010520610992\n"
          ]
        }
      ],
      "source": [
        "pred = model3.predict(X_orig_valid)\n",
        "for i in range(Y3_valid.shape[1]):\n",
        "    print(\"score for col \",i,\": \" , 0.5 + 0.5 * np.maximum(0, metrics.r2_score(Y3_valid[i], pred[i])))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Writing results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "l02c01_celsius_to_fahrenheit.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
