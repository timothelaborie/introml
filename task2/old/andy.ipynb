{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.metrics as metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18995, 420)\n",
      "(18995, 15)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"train_features_normalized.csv\")\n",
    "DATA = np.array(data.iloc[:, 2:].values, dtype=float)\n",
    "DATA = DATA.reshape(227940//12,35*12)\n",
    "\n",
    "data_bin = pd.read_csv(\"train_labels.csv\")\n",
    "DATA_BIN = np.array(data_bin.iloc[:, 1:].values, dtype=float)\n",
    "\n",
    "test = pd.read_csv(\"test_features_normalized.csv\")\n",
    "TEST = np.array(test.iloc[:, 2:].values, dtype=float)\n",
    "TEST = TEST.reshape(151968//12,35*12)\n",
    "\n",
    "print(DATA.shape)\n",
    "print(DATA_BIN.shape)\n",
    "\n",
    "col_names = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct', 'LABEL_EtCO2', 'LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 and part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    lr.fit(DATA, DATA_BIN[:, i]) #train our logistic regression\n",
    "\n",
    "    Y_pred_lr = lr.predict_proba(TEST)[:,1]\n",
    "    data.append(Y_pred_lr) # we run on our test and put it in the list of arrays\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n",
      "4\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 96.8364 - mean_squared_error: 96.8364\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 52.7871 - mean_squared_error: 52.7871\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 49.2722 - mean_squared_error: 49.2722\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 48.6559 - mean_squared_error: 48.6559\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 46.8238 - mean_squared_error: 46.8238\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 49.5169 - mean_squared_error: 49.5169\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 45.6270 - mean_squared_error: 45.6270\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 46.5884 - mean_squared_error: 46.5884\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 46.4208 - mean_squared_error: 46.4208\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 46.4386 - mean_squared_error: 46.4386\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 47.3508 - mean_squared_error: 47.3508\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 45.4122 - mean_squared_error: 45.4122\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 45.5788 - mean_squared_error: 45.5788\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 45.9725 - mean_squared_error: 45.9725\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 46.1332 - mean_squared_error: 46.1332\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 45.5175 - mean_squared_error: 45.5175\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 44.9149 - mean_squared_error: 44.9149\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 44.9051 - mean_squared_error: 44.9051\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 44.6347 - mean_squared_error: 44.6347\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 44.3614 - mean_squared_error: 44.3614\n"
     ]
    }
   ],
   "source": [
    "output_train = DATA_BIN[:, 11:]\n",
    "\n",
    "inputs_dim = DATA.shape[1]\n",
    "outputs_dim = output_train.shape[1]\n",
    "\n",
    "print(inputs_dim)\n",
    "print(outputs_dim)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(units=100, input_shape=[inputs_dim], activation='relu'),\n",
    "  tf.keras.layers.Dense(units=25, activation='relu'),\n",
    "  tf.keras.layers.Dense(units=outputs_dim)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1), metrics=['mean_squared_error'])\n",
    "model.fit(DATA, output_train, epochs=20)\n",
    "\n",
    "pred = model.predict(TEST)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "data.extend(pred.transpose().tolist())\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as CSV and Zipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data).transpose()\n",
    "new_df = pd.DataFrame(np_array, columns=col_names)\n",
    "\n",
    "\n",
    "output_csv = pd.read_csv(\"output.csv\")\n",
    "output_csv.update(new_df)\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='out.csv', )  \n",
    "output_csv.to_csv('out.zip', index=False,\n",
    "          compression=compression_opts, float_format='%.3f')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "079c57ae1d36b41676800ba84e6226da45cdb3a590a228cc31c0829722b6442a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
