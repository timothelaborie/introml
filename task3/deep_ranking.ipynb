{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "from  __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from ImageDataGeneratorCustom import ImageDataGeneratorCustom\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convnet_model_():\n",
    "    model = tf.keras.Sequential([\n",
    "        #VGG16\n",
    "        tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3)),\n",
    "        #GlobalAveragePooling2D\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        #Dense 4096 relu\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        #Dropout 0.5\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        #Dense 4096 relu\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        #Dropout 0.5\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        #L2 normalization\n",
    "        tf.keras.layers.Lambda(lambda  x: K.l2_normalize(x,axis=1))\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "def deep_rank_model():\n",
    " \n",
    "    convnet_model = convnet_model_()\n",
    "    first_input = Input(shape=(224,224,3))\n",
    "    first_conv = Conv2D(96, kernel_size=(8, 8),strides=(16,16), padding='same')(first_input)\n",
    "    first_max = MaxPool2D(pool_size=(3,3),strides = (4,4),padding='same')(first_conv)\n",
    "    first_max = Flatten()(first_max)\n",
    "    first_max = Lambda(lambda  x: K.l2_normalize(x,axis=1))(first_max)\n",
    "\n",
    "    second_input = Input(shape=(224,224,3))\n",
    "    second_conv = Conv2D(96, kernel_size=(8, 8),strides=(32,32), padding='same')(second_input)\n",
    "    second_max = MaxPool2D(pool_size=(7,7),strides = (2,2),padding='same')(second_conv)\n",
    "    second_max = Flatten()(second_max)\n",
    "    second_max = Lambda(lambda  x: K.l2_normalize(x,axis=1))(second_max)\n",
    "\n",
    "    merge_one = concatenate([first_max, second_max])\n",
    "\n",
    "    merge_two = concatenate([merge_one, convnet_model.output])\n",
    "    emb = Dense(4096)(merge_two)\n",
    "    l2_norm_final = Lambda(lambda  x: K.l2_normalize(x,axis=1))(emb)\n",
    "\n",
    "    final_model = Model(inputs=[first_input, second_input, convnet_model.input], outputs=l2_norm_final)\n",
    "\n",
    "    return final_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16_input [(None, 224, 224, 3)]\n",
      "vgg16 (None, 7, 7, 512)\n",
      "input_5 [(None, 224, 224, 3)]\n",
      "input_6 [(None, 224, 224, 3)]\n",
      "global_average_pooling2d_1 (None, 512)\n",
      "conv2d_2 (None, 14, 14, 96)\n",
      "conv2d_3 (None, 7, 7, 96)\n",
      "dense_3 (None, 4096)\n",
      "max_pooling2d_2 (None, 4, 4, 96)\n",
      "max_pooling2d_3 (None, 4, 4, 96)\n",
      "dropout_2 (None, 4096)\n",
      "flatten_2 (None, 1536)\n",
      "flatten_3 (None, 1536)\n",
      "dense_4 (None, 4096)\n",
      "lambda_5 (None, 1536)\n",
      "lambda_6 (None, 1536)\n",
      "dropout_3 (None, 4096)\n",
      "concatenate_2 (None, 3072)\n",
      "lambda_4 (None, 4096)\n",
      "concatenate_3 (None, 7168)\n",
      "dense_5 (None, 4096)\n",
      "lambda_7 (None, 4096)\n"
     ]
    }
   ],
   "source": [
    "deep_rank_model = deep_rank_model()\n",
    "\n",
    "for layer in deep_rank_model.layers:\n",
    "    print (layer.name, layer.output_shape)\n",
    "\n",
    "model_path = \"./deep_ranking\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "    def __init__(self, params, target_size=(224, 224)):\n",
    "        self.params = params\n",
    "        self.target_size = target_size\n",
    "        self.idg = ImageDataGeneratorCustom(**params)\n",
    "\n",
    "    def get_train_generator(self, batch_size):\n",
    "        return self.idg.flow_from_directory(\"./food_224/\",\n",
    "                                            batch_size=batch_size,\n",
    "                                            target_size=self.target_size,shuffle=False,\n",
    "                                            triplet_path  ='./train_triplets.txt'\n",
    "                                           )\n",
    "\n",
    "    def get_test_generator(self, batch_size):\n",
    "        return self.idg.flow_from_directory(\"./food_224/\",\n",
    "                                            batch_size=batch_size,\n",
    "                                            target_size=self.target_size, shuffle=False,\n",
    "                                            triplet_path  ='./test_triplets.txt'\n",
    "                                        )\n",
    "\n",
    "\n",
    "\n",
    "dg = DataGenerator({\n",
    "    \"rescale\": 1. / 255,\n",
    "    \"horizontal_flip\": True,\n",
    "    # \"vertical_flip\": True,\n",
    "    \"zoom_range\": 0.2,\n",
    "    \"shear_range\": 0.2,\n",
    "    \"rotation_range\": 30,\n",
    "    \"fill_mode\": 'nearest' \n",
    "}, target_size=(224, 224))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8 \n",
    "batch_size *= 3\n",
    "train_generator = dg.get_train_generator(batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_EPSILON = K.epsilon()\n",
    "def _loss_tensor(y_true, y_pred):\n",
    "    y_pred = K.clip(y_pred, _EPSILON, 1.0-_EPSILON)\n",
    "    loss =  tf.convert_to_tensor(0,dtype=tf.float32)\n",
    "    g = tf.constant(1.0, shape=[1], dtype=tf.float32)\n",
    "    for i in range(0,batch_size,3):\n",
    "        try:\n",
    "            q_embedding = y_pred[i+0]\n",
    "            p_embedding =  y_pred[i+1]\n",
    "            n_embedding = y_pred[i+2]\n",
    "            D_q_p =  K.sqrt(K.sum((q_embedding - p_embedding)**2))\n",
    "            D_q_n = K.sqrt(K.sum((q_embedding - n_embedding)**2))\n",
    "            loss = (loss + g + D_q_p - D_q_n )            \n",
    "        except:\n",
    "            continue\n",
    "    loss = loss/(batch_size/3)\n",
    "    zero = tf.constant(0.0, shape=[1], dtype=tf.float32)\n",
    "    return tf.maximum(loss,zero)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timothe\\AppData\\Local\\Temp/ipykernel_20472/13994253.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  deep_rank_model.fit_generator(train_generator,\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20472/13994253.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_steps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m59515\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtrain_epocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m deep_rank_model.fit_generator(train_generator,\n\u001b[0m\u001b[0;32m      8\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_steps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_epocs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2207\u001b[0m         \u001b[1;34m'Please use `Model.fit`, which supports generators.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2208\u001b[0m         stacklevel=2)\n\u001b[1;32m-> 2209\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   2210\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Timothe\\Documents\\GitHub\\introml\\task3\\ImageDataGeneratorCustom.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Timothe\\Documents\\GitHub\\introml\\task3\\ImageDataGeneratorCustom.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1021\u001b[0m         \u001b[1;31m# build batch of image data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1023\u001b[1;33m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1024\u001b[0m             img = load_img(os.path.join(self.directory, fname),\n\u001b[0;32m   1025\u001b[0m                            \u001b[0mgrayscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrayscale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#deep_rank_model.load_weights('deepranking.h5')\n",
    "deep_rank_model.compile(loss=_loss_tensor, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "train_steps_per_epoch = int((59515)/batch_size)\n",
    "train_epochs = 25\n",
    "deep_rank_model.fit_generator(train_generator,\n",
    "                        steps_per_epoch=train_steps_per_epoch,\n",
    "                        epochs=train_epochs\n",
    "                        )\n",
    "\n",
    "model_path = \"deepranking.h5\"\n",
    "deep_rank_model.save_weights(model_path)\n",
    "#f = open('deepranking.json','w')\n",
    "#f.write(deep_rank_model.to_json())\n",
    "#f.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
