{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oSdjGwVWGshH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.12.1+cu116\n",
            "torch detects GPU:  True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from transformers import ViTFeatureExtractor, ViTModel\n",
        "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
        "from scipy.special import softmax\n",
        "\n",
        "IMG_SHAPE = 224\n",
        "\n",
        "import torch\n",
        "import clip\n",
        "print(torch.__version__)\n",
        "print(\"torch detects GPU: \" , torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "# Resizing the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ssD23VbTZeVA"
      },
      "outputs": [],
      "source": [
        "# load every image in the food folder and resize them to 224x224, then save them in a new folder\n",
        "\n",
        "# for filename in os.listdir('food'):\n",
        "#     img = Image.open('food/' + filename)\n",
        "#     img = img.resize((IMG_SHAPE, IMG_SHAPE))\n",
        "#     img.save('food_'+str(IMG_SHAPE)+'/' + filename)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extracting the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 1024)\n",
            "[[-0.9790746   2.6313405  -0.21268739 ...  0.3248024  -0.08107211\n",
            "   0.30868477]]\n"
          ]
        }
      ],
      "source": [
        "image = Image.open('food_'+str(IMG_SHAPE)+'/00007.jpg')\n",
        "\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"nateraw/food\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\"nateraw/food\")\n",
        "\n",
        "# feature_extractor = AutoFeatureExtractor.from_pretrained(\"aspis/swin-finetuned-food101\")\n",
        "# model = AutoModelForImageClassification.from_pretrained(\"aspis/swin-finetuned-food101\")\n",
        "\n",
        "#put the models on the GPU\n",
        "# feature_extractor = feature_extractor.to('cuda')\n",
        "model = model.to('cuda')\n",
        "# print(model)\n",
        "\n",
        "#remove the classifier layer\n",
        "model.classifier = torch.nn.Identity()\n",
        "# model.vit.layernorm = torch.nn.Identity()\n",
        "# print(model)\n",
        "\n",
        "with torch.no_grad():\n",
        "    np.set_printoptions(suppress=True)\n",
        "    inputs = feature_extractor(images=image, return_tensors=\"pt\").to('cuda')\n",
        "    # print(inputs)\n",
        "    outputs = model(**inputs)\n",
        "    # soft = outputs.logits.softmax(dim=-1).cpu().numpy()\n",
        "    # print(np.argmax(soft))\n",
        "    # print(outputs)\n",
        "    print(outputs.logits.cpu().numpy().shape)\n",
        "    print(outputs.logits.cpu().numpy())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n"
          ]
        }
      ],
      "source": [
        "# dictionary with all the image names and their features\n",
        "features = {}\n",
        "\n",
        "# convert every image into features\n",
        "line_id = 0\n",
        "for filename in os.listdir('food_'+str(IMG_SHAPE)+''):\n",
        "    id = int(filename.replace(\".jpg\", \"\"))\n",
        "    # print(id)\n",
        "    line_id += 1\n",
        "    image = Image.open('food_'+str(IMG_SHAPE)+'/' + filename)\n",
        "    with torch.no_grad():\n",
        "        inputs = feature_extractor(images=image, return_tensors=\"pt\").to('cuda')\n",
        "        feature = model(**inputs).logits\n",
        "        feature = np.array(feature.cpu().numpy(), dtype=np.float32)\n",
        "        feature = feature.reshape(-1)\n",
        "        features[filename.replace(\".jpg\",\"\")] = feature\n",
        "        # print(feature[0])\n",
        "        if line_id % 100 == 0:\n",
        "            print(line_id)\n",
        "            # break\n",
        "        if id == 5001:\n",
        "            break\n",
        "\n",
        "# save the features dictionary to a file using pickle\n",
        "with open('features_vit.pickle', 'wb') as handle:\n",
        "# with open('features_swin.pickle', 'wb') as handle:\n",
        "    pickle.dump(features, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1024,)\n",
            "[ 1.6176932 -0.3299582 -0.1449341 ... -1.4465858  2.7391245 -1.6128058]\n",
            "1.6176932\n",
            "2.0003452\n",
            "-2.1996455\n",
            "5002\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# features = {}\n",
        "# with open('features_mn.pickle', 'rb') as handle:\n",
        "#     features = pickle.load(handle)\n",
        "    \n",
        "print(features['00000'].shape)\n",
        "print(features['00000'])\n",
        "print(np.array(features['00000'][0], dtype=np.float32))\n",
        "print(np.array(features['00001'][0], dtype=np.float32))\n",
        "print(np.array(features['00002'][0], dtype=np.float32))\n",
        "print(len(features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# features = {}\n",
        "\n",
        "# with open('features_vit2.pickle', 'rb') as handle:\n",
        "#     features = pickle.load(handle)\n",
        "#     for key in features:\n",
        "#         features[key] = softmax(features[key])\n",
        "#     # print(np.array(features['00000'], dtype=np.float32))\n",
        "#     # print(np.array(features['00001'][0], dtype=np.float32))\n",
        "#     # print(np.array(features['00002'][0], dtype=np.float32))\n",
        "\n",
        "\n",
        "# with open('features_vit3.pickle', 'wb') as handle:\n",
        "#     pickle.dump(features, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "l05c01_dogs_vs_cats_without_augmentation.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
