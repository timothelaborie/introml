{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oSdjGwVWGshH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.12.1+cu116\n",
            "torch detects GPU:  True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from transformers import ViTFeatureExtractor, ViTModel\n",
        "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
        "from scipy.special import softmax\n",
        "\n",
        "IMG_SHAPE = 224\n",
        "\n",
        "import torch\n",
        "import clip\n",
        "print(torch.__version__)\n",
        "print(\"torch detects GPU: \" , torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "# Resizing the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ssD23VbTZeVA"
      },
      "outputs": [],
      "source": [
        "# load every image in the food folder and resize them to 224x224, then save them in a new folder\n",
        "\n",
        "# for filename in os.listdir('food'):\n",
        "#     img = Image.open('food/' + filename)\n",
        "#     img = img.resize((IMG_SHAPE, IMG_SHAPE))\n",
        "#     img.save('food_'+str(IMG_SHAPE)+'/' + filename)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extracting the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 101)\n",
            "[[-0.10903698  0.7071282  -0.1231105  -0.48549244 -0.10596184 -0.34187785\n",
            "   0.27113667 -0.31629828  1.0921512  -0.27079928 -1.7905712  -0.17101659\n",
            "   0.13042854 -0.5239889   1.7427368  -0.19157255 -0.7800584   1.1850092\n",
            "   0.13878821 -0.34238803 -0.15138647 10.107201    2.871378    0.37200615\n",
            "  -0.9084653  -0.40659168 -0.7088722  -0.24617077 -0.3055647   0.9293847\n",
            "  -0.31592616  1.161826   -0.4173769  -0.5094079  -0.8763412  -0.7942207\n",
            "   0.07240397  0.67694217  0.5420245  -1.3170156  -0.35400978 -0.5168432\n",
            "   0.17636983 -0.37139076  0.0949786  -0.8484421   0.20012502 -1.0307158\n",
            "   0.12617676 -0.4830395  -0.49172133  0.20857431 -0.86916643  0.15447226\n",
            "  -0.2308073  -0.45156053 -0.69761574 -0.6635288  -0.25926018 -0.17530335\n",
            "  -0.7440919   0.11873879 -0.74085987  0.42552963 -0.04901424 -0.67083704\n",
            "   0.4520535  -0.40815505 -0.33330125 -0.8885472   0.35710278  0.59184206\n",
            "  -0.16199313 -0.32626444 -0.2956888   0.01370557 -0.38568968 -0.1664199\n",
            "  -0.5671209   0.42489588 -0.38085413 -0.5041495  -0.46023723  3.0061738\n",
            "  -0.48306453 -0.258627   -0.5496179  -1.3146894  -0.18184647 -0.60735023\n",
            "   0.10036498 -0.28558776 -0.6481283   0.25677797  0.365633   -0.26377955\n",
            "   0.36298567 -1.1702921   1.2421936   0.56225526 -0.3405346 ]]\n"
          ]
        }
      ],
      "source": [
        "image = Image.open('food_'+str(IMG_SHAPE)+'/00007.jpg')\n",
        "\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"nateraw/food\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\"nateraw/food\")\n",
        "\n",
        "#put the models on the GPU\n",
        "# feature_extractor = feature_extractor.to('cuda')\n",
        "model = model.to('cuda')\n",
        "\n",
        "#remove the classifier layer\n",
        "model.classifier = torch.nn.Identity()\n",
        "model.vit.layernorm = torch.nn.Identity()\n",
        "# print(model)\n",
        "\n",
        "with torch.no_grad():\n",
        "    np.set_printoptions(suppress=True)\n",
        "    inputs = feature_extractor(images=image, return_tensors=\"pt\").to('cuda')\n",
        "    # print(inputs)\n",
        "    outputs = model(**inputs)\n",
        "    # soft = outputs.logits.softmax(dim=-1).cpu().numpy()\n",
        "    # print(np.argmax(soft))\n",
        "    # print(outputs)\n",
        "    print(outputs.logits.cpu().numpy().shape)\n",
        "    print(outputs.logits.cpu().numpy())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n"
          ]
        }
      ],
      "source": [
        "# dictionary with all the image names and their features\n",
        "features = {}\n",
        "\n",
        "# convert every image into features\n",
        "line_id = 0\n",
        "for filename in os.listdir('food_'+str(IMG_SHAPE)+''):\n",
        "    id = int(filename.replace(\".jpg\", \"\"))\n",
        "    # print(id)\n",
        "    line_id += 1\n",
        "    image = Image.open('food_'+str(IMG_SHAPE)+'/' + filename)\n",
        "    with torch.no_grad():\n",
        "        inputs = feature_extractor(images=image, return_tensors=\"pt\").to('cuda')\n",
        "        feature = model(**inputs).logits\n",
        "        feature = np.array(feature.cpu().numpy(), dtype=np.float32)\n",
        "        feature = feature.reshape(-1)\n",
        "        features[filename.replace(\".jpg\",\"\")] = feature\n",
        "        # print(feature[0])\n",
        "        if line_id % 100 == 0:\n",
        "            print(line_id)\n",
        "            # break\n",
        "        if id == 5001:\n",
        "            break\n",
        "\n",
        "# save the features dictionary to a file using pickle\n",
        "with open('features_vit.pickle', 'wb') as handle:\n",
        "    pickle.dump(features, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(101,)\n",
            "[-0.15641706 -0.04846567 -0.5680937  -0.30306917 -0.2759278   1.1834544\n",
            " -0.90819067  0.34527883 -0.3602629  -0.06251695 -0.26097277  0.46102375\n",
            " -0.7009203  -0.23648539 -0.2765711  -0.4013498  -0.2639648  -0.30348867\n",
            "  0.32166398  0.35783684 -0.37837955 -0.03505383 -0.36808982  0.53418356\n",
            " -0.9663702  -0.18616615  0.12631494 -0.19195983  0.22505593 -0.29878506\n",
            " -0.4233447   0.03000382  0.07663471  2.429741   -0.90852755 -0.23284523\n",
            "  0.07362539  1.3784795  -0.08516523 -0.46301675  1.0649537  -0.17978667\n",
            " -0.8194879   0.17889462 -0.04968277 -1.2409251   0.09764299 -0.20737815\n",
            "  1.2718052  -0.4931599   1.0167762   0.17911531  1.1381528   0.22722667\n",
            "  0.37812662 -0.97233623 -0.9378077  -0.37787005 -0.3437252  -0.84179485\n",
            " -1.0167674  -1.1358867   0.30492723  0.32368082  0.54670167  1.226591\n",
            " -0.07247812 -0.6632689  -0.5457843  -0.22663414  1.6898233  -0.40640193\n",
            " -0.7198109  -0.01986106 -0.44494003  0.44223353 -0.06518041 -0.299631\n",
            "  0.5368905  -0.05286302  0.21921077 -0.27373835  0.07202477 -0.45282945\n",
            " -0.1927091   0.24693826 -0.22890095 -0.4770457   8.850124   -0.22034538\n",
            " -0.2713326  -0.41298318  0.1632205  -0.18239997 -1.1752003   0.10635093\n",
            " -0.80954707 -0.56789124 -0.40977353  0.18514359 -0.3540338 ]\n",
            "-0.15641706\n",
            "3.484027\n",
            "0.4884698\n",
            "5002\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# features = {}\n",
        "# with open('features_mn.pickle', 'rb') as handle:\n",
        "#     features = pickle.load(handle)\n",
        "    \n",
        "print(features['00000'].shape)\n",
        "print(features['00000'])\n",
        "print(np.array(features['00000'][0], dtype=np.float32))\n",
        "print(np.array(features['00001'][0], dtype=np.float32))\n",
        "print(np.array(features['00002'][0], dtype=np.float32))\n",
        "print(len(features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# features = {}\n",
        "\n",
        "# with open('features_vit2.pickle', 'rb') as handle:\n",
        "#     features = pickle.load(handle)\n",
        "#     for key in features:\n",
        "#         features[key] = softmax(features[key])\n",
        "#     # print(np.array(features['00000'], dtype=np.float32))\n",
        "#     # print(np.array(features['00001'][0], dtype=np.float32))\n",
        "#     # print(np.array(features['00002'][0], dtype=np.float32))\n",
        "\n",
        "\n",
        "# with open('features_vit3.pickle', 'wb') as handle:\n",
        "#     pickle.dump(features, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "l05c01_dogs_vs_cats_without_augmentation.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
