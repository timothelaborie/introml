{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "# Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oSdjGwVWGshH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import logging\n",
        "from tensorflow.python.client import device_lib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_hub as hub\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import shutil\n",
        "\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "print(tf.__version__)\n",
        "\n",
        "# IMG_SHAPE = 192\n",
        "# IMG_SHAPE = 224\n",
        "IMG_SHAPE = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "# Resizing the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ssD23VbTZeVA"
      },
      "outputs": [],
      "source": [
        "# load every image in the food folder and resize them to 224x224, then save them in a new folder\n",
        "\n",
        "# for filename in os.listdir('food'):\n",
        "#     img = Image.open('food/' + filename)\n",
        "#     img = img.resize((IMG_SHAPE, IMG_SHAPE))\n",
        "#     img.save('food_'+str(IMG_SHAPE)+'/' + filename)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extracting the features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### IMPORTANT: the code needs to be run twice with the right image size, to generate features with both extractors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_3 (KerasLayer)  (None, 2048)              23500352  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,500,352\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,500,352\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#efficientnetXL (needs 512x512)\n",
        "# feature_extractor = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_xl/feature_vector/2\", input_shape=(IMG_SHAPE, IMG_SHAPE,3),trainable=False)\n",
        "\n",
        "#food extractor with resnet (needs 512x512)\n",
        "feature_extractor = hub.KerasLayer(\"https://tfhub.dev/google/experts/bit/r50x1/in21k/food/1\", input_shape=(IMG_SHAPE, IMG_SHAPE,3),trainable=False)\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  feature_extractor,\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 512, 512, 3)\n",
            "[[0.02066039 0.         0.4547058  ... 0.34155965 1.0545528  0.26238483]]\n"
          ]
        }
      ],
      "source": [
        "# img = np.array(Image.open('food_'+str(IMG_SHAPE)+'/00001.jpg'))[None]*1.0/255\n",
        "# print(img.shape)\n",
        "# output = model.predict(img)\n",
        "# # print(output.shape)\n",
        "# print(output)\n",
        "# # print(img[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25.08255\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# for filename in os.listdir('food_'+str(IMG_SHAPE)+''):\n",
        "#     name = filename.replace(\".jpg\",\"\")\n",
        "#     if(name != \"02463\"):\n",
        "#         continue\n",
        "\n",
        "#     img = Image.open('food_'+str(IMG_SHAPE)+'/' + filename)\n",
        "#     img = np.array(img)*1.0/255\n",
        "#     feature = model.predict(img[None])[0]\n",
        "#     print(np.max(feature))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "8000\n",
            "8100\n",
            "8200\n",
            "8300\n",
            "8400\n",
            "8500\n",
            "8600\n",
            "8700\n",
            "8800\n",
            "8900\n",
            "9000\n",
            "9100\n",
            "9200\n",
            "9300\n",
            "9400\n",
            "9500\n",
            "9600\n",
            "9700\n",
            "9800\n",
            "9900\n",
            "10000\n"
          ]
        }
      ],
      "source": [
        "# dictionary with all the image names and their features\n",
        "features = {}\n",
        "\n",
        "# convert every image into features\n",
        "line_id = 0\n",
        "for filename in os.listdir('food_'+str(IMG_SHAPE)+''):\n",
        "    id = int(filename.replace(\".jpg\", \"\"))\n",
        "    line_id += 1\n",
        "    img = Image.open('food_'+str(IMG_SHAPE)+'/' + filename)\n",
        "    img = np.array(img)*1.0/255\n",
        "    feature = model.predict(img[None])[0]\n",
        "    features[filename.replace(\".jpg\",\"\")] = feature\n",
        "    if line_id % 100 == 0:\n",
        "        print(line_id)\n",
        "    # if id == 5001:\n",
        "    #     break\n",
        "\n",
        "# save the features dictionary to a file using pickle\n",
        "with open('features_resnet.pickle', 'wb') as handle:\n",
        "    pickle.dump(features, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3.2279101e-01 1.6950681e-03 2.0503240e+00 ... 1.2365297e+00 1.3910511e+00\n",
            " 9.2304796e-01]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# features = {}\n",
        "# with open('features_mn.pickle', 'rb') as handle:\n",
        "#     features = pickle.load(handle)\n",
        "    \n",
        "print(features['02461'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n",
            "2048\n"
          ]
        }
      ],
      "source": [
        "print(len(features))\n",
        "print(len(features[\"00000\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1280\n",
            "768\n",
            "2048\n",
            "768\n",
            "5002\n",
            "4864\n"
          ]
        }
      ],
      "source": [
        "# features1 = {}\n",
        "# features2 = {}\n",
        "# features3 = {}\n",
        "# features4 = {}\n",
        "# with open('features_xl.pickle', 'rb') as handle:\n",
        "#     features1 = pickle.load(handle)\n",
        "#     print(len(features1[\"00000\"]))\n",
        "# with open('features_vit.pickle', 'rb') as handle:\n",
        "#     features2 = pickle.load(handle)\n",
        "#     print(len(features2[\"00000\"]))\n",
        "# with open('features_resnet.pickle', 'rb') as handle:\n",
        "#     features3 = pickle.load(handle)\n",
        "#     print(len(features3[\"00000\"]))\n",
        "# with open('features_clip.pickle', 'rb') as handle:\n",
        "#     features4 = pickle.load(handle)\n",
        "#     print(len(features4[\"00000\"]))\n",
        "\n",
        "# features_merged = {}\n",
        "# for key in features1:\n",
        "#     id = int(key.replace(\".jpg\", \"\"))\n",
        "#     features_merged[key] = np.concatenate((features1[key],features2[key],features3[key],features4[key]))\n",
        "#     if id == 5001:\n",
        "#         break\n",
        "\n",
        "# print(len(features_merged))\n",
        "# print(len(features_merged[\"05000\"]))\n",
        "\n",
        "# with open('features_merged.pickle', 'wb') as handle:\n",
        "#     pickle.dump(features_merged, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "l05c01_dogs_vs_cats_without_augmentation.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
