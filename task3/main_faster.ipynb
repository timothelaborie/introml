{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "from  __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from ImageDataGeneratorCustom import ImageDataGeneratorCustom\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "import tensorflow_hub as hub\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import shutil\n",
    "from tensorflow import debugging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from keras import applications\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "from keras import metrics\n",
    "from keras import Model\n",
    "from keras.applications import resnet\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_addons as tfa\n",
    "from keras.regularizers import l2\n",
    "from keras.activations import *\n",
    "\n",
    "\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# tf.config.run_functions_eagerly(True)\n",
    "# tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "model_path = \"./deep_ranking\"\n",
    "\n",
    "# batch_size = 96\n",
    "# batch_size = 8\n",
    "batch_size = 24\n",
    "# batch_size = 3\n",
    "# batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a lot of the code comes from https://keras.io/examples/vision/siamese_network/\n",
    "and https://github.com/akarshzingade/image-similarity-deep-ranking/blob/master/deepRanking.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "embedding = tf.keras.Sequential([\n",
    "    # tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    # tf.keras.layers.Dense(256, activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    # tf.keras.layers.Dense(256, activation='linear'),\n",
    "\n",
    "    # GlobalAveragePooling2D(),\n",
    "\n",
    "    # tf.keras.layers.Dense(1024, activation='linear'),\n",
    "\n",
    "\n",
    "    Dense(4096, activation=ReLU, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),\n",
    "    Dropout(0.6),\n",
    "    Dense(4096, activation=ReLU, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),\n",
    "    Dropout(0.6),\n",
    "\n",
    "    # tf.keras.layers.Dense(8192, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    # tf.keras.layers.Dropout(0.6),\n",
    "    # tf.keras.layers.Dense(8192, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    # tf.keras.layers.Dropout(0.6),\n",
    "    # tf.keras.layers.Dense(8192, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    # tf.keras.layers.Dropout(0.6),\n",
    "    # tf.keras.layers.Dense(8192, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    # tf.keras.layers.Dropout(0.6),\n",
    "    Lambda(lambda  x: K.l2_normalize(x,axis=1))\n",
    "])\n",
    "\n",
    "class DistanceLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer is responsible for computing the distance between the anchor\n",
    "    embedding and the positive embedding, and the anchor embedding and the\n",
    "    negative embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "        return (ap_distance, an_distance)\n",
    "\n",
    "\n",
    "anchor_input = layers.Input(name=\"anchor\", shape=(1280))\n",
    "positive_input = layers.Input(name=\"positive\", shape=(1280))\n",
    "negative_input = layers.Input(name=\"negative\", shape=(1280))\n",
    "\n",
    "distances = DistanceLayer()(\n",
    "    embedding(anchor_input),\n",
    "    embedding(positive_input),\n",
    "    embedding(negative_input),\n",
    ")\n",
    "\n",
    "model = Model(\n",
    "    inputs=[anchor_input, positive_input, negative_input], outputs=distances\n",
    ")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = 2\n",
    "# pred = model.predict((np.random.rand(imgs,1280),np.random.rand(imgs,1280),np.random.rand(imgs,1280)))\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "# load the features dictionary from the file\n",
    "with open('features_xl.pickle', 'rb') as handle:\n",
    "    features = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14465111  0.09083702  0.41782254 ...  2.7458491   1.6808972\n",
      " -0.00417358]\n",
      "(1280,)\n"
     ]
    }
   ],
   "source": [
    "print(features[\"02461\"])\n",
    "print(features[\"02461\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the features dictionary to a tensorflow hash table\n",
    "keys = tf.constant([key for key in features.keys()])\n",
    "values = tf.constant([val for val in features.values()])\n",
    "\n",
    "table = tf.lookup.experimental.DenseHashTable(\n",
    "    value_dtype=tf.float32,\n",
    "    key_dtype=tf.string,\n",
    "    empty_key=\"empty_key\",\n",
    "    deleted_key=\"deleted_key\",\n",
    "    default_value=[-1]*1280,\n",
    "    )\n",
    "\n",
    "table.insert(keys, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load strings from train_triplets.txt\n",
    "train_triplets = np.loadtxt('./train_triplets.txt', dtype=str,delimiter = ' ')\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(train_triplets)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def load_image(inputs):\n",
    "    filenames = inputs\n",
    "    # print(filenames)\n",
    "\n",
    "\n",
    "    # print(table[filenames[0]])\n",
    "    anchor = table[filenames[0]]\n",
    "    positive = table[filenames[1]]\n",
    "    negative = table[filenames[2]]\n",
    "\n",
    "    output = (anchor,positive,negative)\n",
    "    \n",
    "    return output\n",
    "\n",
    "dataset = dataset.map(load_image).cache().shuffle(buffer_size=1000).batch(batch_size).prefetch(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a,p,n = np.loadtxt('./train_triplets.txt', dtype=str,delimiter = ' ',unpack=True)\n",
    "# print(a.shape)\n",
    "\n",
    "# train_triplets = ([features[s] for s in a], [features[s] for s in p], [features[s] for s in n])\n",
    "# print(len(train_triplets))\n",
    "# print(len(train_triplets[0]))\n",
    "# print(len(train_triplets[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.from_tensor_slices(train_triplets)\n",
    "\n",
    "# dataset = dataset.cache().batch(batch_size).prefetch(300*batch_size)#.shuffle(300*batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
    "# def plotImages(images_arr):\n",
    "#     fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "#     axes = axes.flatten()\n",
    "#     for img, ax in zip(images_arr, axes):\n",
    "#         ax.imshow(img)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# augmented_images = [my_gen[0][0][0] for i in range(5)]\n",
    "# plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(Model):\n",
    "    \"\"\"The Siamese Network model with a custom training and testing loops.\n",
    "\n",
    "    Computes the triplet loss using the three embeddings produced by the\n",
    "    Siamese Network.\n",
    "\n",
    "    The triplet loss is defined as:\n",
    "       L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, siamese_network, margin=0.5):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # GradientTape is a context manager that records every operation that\n",
    "        # you do inside. We are using it here to compute the loss so we can get\n",
    "        # the gradients and apply them using the optimizer specified in\n",
    "        # `compile()`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        # Storing the gradients of the loss function with respect to the\n",
    "        # weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siamese_network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        # Let's update and return the loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        # The output of the network is a tuple containing the distances\n",
    "        # between the anchor and the positive example, and the anchor and\n",
    "        # the negative example.\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "\n",
    "        # Computing the Triplet Loss by subtracting both distances and\n",
    "        # making sure we don't get a negative value.\n",
    "        loss = ap_distance - an_distance\n",
    "        loss = tf.maximum(loss + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = SiameseModel(model,margin=0.5)\n",
    "# siamese_model.compile(optimizer=tf.keras.optimizers.Adam(0.0001))\n",
    "# siamese_model.compile(optimizer=tf.keras.optimizers.Adam(0.0000005))\n",
    "siamese_model.compile(optimizer=tf.keras.optimizers.Adam(0.000001))\n",
    "\n",
    "\n",
    "# class MyExponentialDecay(tf.keras.optimizers.schedules.ExponentialDecay):\n",
    "#   def __call__(self, step):\n",
    "#     return 1e-2 * super().__call__(step)\n",
    "\n",
    "# initial_learning_rate = 1e-2\n",
    "# wd = MyExponentialDecay(\n",
    "#     initial_learning_rate,\n",
    "#     decay_steps=14,\n",
    "#     decay_rate=0.8,\n",
    "#     staircase=True)\n",
    "\n",
    "\n",
    "# step = tf.Variable(0, trainable=False)\n",
    "# schedule = tf.optimizers.schedules.PiecewiseConstantDecay([10000, 15000], [1e-0, 1e-1, 1e-2])\n",
    "# lr = 1e-1 * schedule(step)\n",
    "# # wd = lambda: 1e-4 * schedule(step)\n",
    "# opt = tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd)\n",
    "\n",
    "# siamese_model.compile(optimizer=opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1.0158019 , 0.9109661 , 1.2380718 , 0.8157411 , 1.1505013 ,\n",
      "       1.1772248 , 1.097458  , 0.70524263, 1.029724  , 0.67237407,\n",
      "       1.0944903 , 1.1234801 , 1.1208537 , 0.76909935, 0.68197465,\n",
      "       1.1969228 , 0.9064738 , 0.78684723, 1.2427619 , 0.7527365 ,\n",
      "       0.9580539 , 1.2804571 , 1.1950073 , 0.8814553 ], dtype=float32), array([1.0534555 , 1.2697401 , 1.1218408 , 1.0091112 , 1.0669051 ,\n",
      "       1.1927825 , 1.001681  , 0.8769452 , 1.1582739 , 0.9604594 ,\n",
      "       0.92310107, 1.2607124 , 0.82224506, 1.2321987 , 1.050529  ,\n",
      "       0.71917474, 1.1692468 , 1.0420399 , 1.1962942 , 0.91715527,\n",
      "       1.1158857 , 1.2549804 , 1.1705428 , 1.0881376 ], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#this is needed, otherwise nothing works\n",
    "pred = siamese_model.predict(next(iter(dataset)))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(my_gen.__getitem__(5)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2480/2480 [==============================] - 42s 17ms/step - loss: 0.3537\n",
      "Epoch 2/1000\n",
      "2480/2480 [==============================] - 44s 18ms/step - loss: 0.2967\n",
      "Epoch 3/1000\n",
      "2480/2480 [==============================] - 45s 18ms/step - loss: 0.2848\n",
      "Epoch 4/1000\n",
      "2480/2480 [==============================] - 41s 17ms/step - loss: 0.2775\n",
      "Epoch 5/1000\n",
      "2480/2480 [==============================] - 39s 16ms/step - loss: 0.2715\n",
      "Epoch 6/1000\n",
      "2480/2480 [==============================] - 37s 15ms/step - loss: 0.2664\n",
      "Epoch 7/1000\n",
      "2480/2480 [==============================] - 35s 14ms/step - loss: 0.2617\n",
      "Epoch 8/1000\n",
      "2480/2480 [==============================] - 33s 13ms/step - loss: 0.2573\n",
      "Epoch 9/1000\n",
      "2480/2480 [==============================] - 34s 14ms/step - loss: 0.2533\n",
      "Epoch 10/1000\n",
      "2480/2480 [==============================] - 36s 14ms/step - loss: 0.2495\n",
      "Epoch 11/1000\n",
      "2480/2480 [==============================] - 33s 13ms/step - loss: 0.2459\n",
      "Epoch 12/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.2424\n",
      "Epoch 13/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.2391\n",
      "Epoch 14/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.2359\n",
      "Epoch 15/1000\n",
      "2480/2480 [==============================] - 31s 13ms/step - loss: 0.2328\n",
      "Epoch 16/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.2298\n",
      "Epoch 17/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.2268\n",
      "Epoch 18/1000\n",
      "2480/2480 [==============================] - 31s 13ms/step - loss: 0.2240\n",
      "Epoch 19/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.2212\n",
      "Epoch 20/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.2185\n",
      "Epoch 21/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.2158\n",
      "Epoch 22/1000\n",
      "2480/2480 [==============================] - 31s 13ms/step - loss: 0.2132\n",
      "Epoch 23/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.2106\n",
      "Epoch 24/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.2081\n",
      "Epoch 25/1000\n",
      "2480/2480 [==============================] - 33s 13ms/step - loss: 0.2056\n",
      "Epoch 26/1000\n",
      "2480/2480 [==============================] - 33s 13ms/step - loss: 0.2032\n",
      "Epoch 27/1000\n",
      "2480/2480 [==============================] - 33s 13ms/step - loss: 0.2009\n",
      "Epoch 28/1000\n",
      "2480/2480 [==============================] - 34s 14ms/step - loss: 0.1985\n",
      "Epoch 29/1000\n",
      "2480/2480 [==============================] - 35s 14ms/step - loss: 0.1962\n",
      "Epoch 30/1000\n",
      "2480/2480 [==============================] - 34s 14ms/step - loss: 0.1940\n",
      "Epoch 31/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1918\n",
      "Epoch 32/1000\n",
      "2480/2480 [==============================] - 34s 14ms/step - loss: 0.1896\n",
      "Epoch 33/1000\n",
      "2480/2480 [==============================] - 33s 13ms/step - loss: 0.1875\n",
      "Epoch 34/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1854\n",
      "Epoch 35/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1833\n",
      "Epoch 36/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1813\n",
      "Epoch 37/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1792\n",
      "Epoch 38/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1773\n",
      "Epoch 39/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1753\n",
      "Epoch 40/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1734\n",
      "Epoch 41/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1714\n",
      "Epoch 42/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1696\n",
      "Epoch 43/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1677\n",
      "Epoch 44/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1659\n",
      "Epoch 45/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1641\n",
      "Epoch 46/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1623\n",
      "Epoch 47/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1605\n",
      "Epoch 48/1000\n",
      "2480/2480 [==============================] - 32s 13ms/step - loss: 0.1588\n",
      "Epoch 49/1000\n",
      "2480/2480 [==============================] - 31s 13ms/step - loss: 0.1571\n",
      "Epoch 50/1000\n",
      "2081/2480 [========================>.....] - ETA: 5s - loss: 0.1561"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Canceled future for execute_request message before replies were done",
     "output_type": "error",
     "traceback": [
      "Error: Canceled future for execute_request message before replies were done",
      "at t.KernelShellFutureHandler.dispose (c:\\Users\\Timothe\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1204175)",
      "at c:\\Users\\Timothe\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1223227",
      "at Map.forEach (<anonymous>)",
      "at v._clearKernelState (c:\\Users\\Timothe\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1223212)",
      "at v.dispose (c:\\Users\\Timothe\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1216694)",
      "at c:\\Users\\Timothe\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:533674",
      "at t.swallowExceptions (c:\\Users\\Timothe\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:913059)",
      "at dispose (c:\\Users\\Timothe\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:533652)",
      "at t.RawSession.dispose (c:\\Users\\Timothe\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:537330)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
     ]
    }
   ],
   "source": [
    "train_steps_per_epoch = int((59520)/batch_size)\n",
    "# train_steps_per_epoch = int((59520*5)/batch_size)\n",
    "\n",
    "# checkpoint_filepath = './checkpoint'\n",
    "checkpoint_filepath = './checkpoints/checkpoint-{epoch}/'\n",
    "# checkpoint_filepath = \"saved-model-{epoch}.hdf5\"\n",
    "# checkpoint_filepath = \"saved-model-{epoch}\"\n",
    "#save checkpoint after every epoch\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    # save_weights_only=True,\n",
    ")\n",
    "\n",
    "\n",
    "siamese_model.fit(dataset, epochs=1000,steps_per_epoch=train_steps_per_epoch,batch_size=batch_size,callbacks=[model_checkpoint_callback])\n",
    "# siamese_model.fit(train_triplets, epochs=2,steps_per_epoch=train_steps_per_epoch,batch_size=batch_size,callbacks=[model_checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model_path = \"siamese_model\"\n",
    "# tf.saved_model.save(siamese_model, model_path)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
