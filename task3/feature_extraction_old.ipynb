{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "# Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oSdjGwVWGshH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import logging\n",
        "from tensorflow.python.client import device_lib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_hub as hub\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import shutil\n",
        "\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "print(tf.__version__)\n",
        "\n",
        "# IMG_SHAPE = 224\n",
        "IMG_SHAPE = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "# Resizing the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ssD23VbTZeVA"
      },
      "outputs": [],
      "source": [
        "# load every image in the food folder and resize them to 224x224, then save them in a new folder\n",
        "\n",
        "for filename in os.listdir('food'):\n",
        "    img = Image.open('food/' + filename)\n",
        "    img = img.resize((IMG_SHAPE, IMG_SHAPE))\n",
        "    img.save('food_'+str(IMG_SHAPE)+'/' + filename)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# everything below is no longer needed (it was used to extract features with mobilenet, to get that 0.61 score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extracting the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_3 (KerasLayer)  (None, 1280)              207615832 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 207,615,832\n",
            "Trainable params: 0\n",
            "Non-trainable params: 207,615,832\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\"\n",
        "# URL = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\"\n",
        "URL = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_xl/feature_vector/2\"\n",
        "\n",
        "feature_extractor = hub.KerasLayer(URL, input_shape=(IMG_SHAPE, IMG_SHAPE,3))\n",
        "feature_extractor.trainable = False\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  feature_extractor,\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 512, 512, 3)\n",
            "(1, 1280)\n"
          ]
        }
      ],
      "source": [
        "img = np.array(Image.open('food_512/00001.jpg'))[None]\n",
        "print(img.shape)\n",
        "output = model.predict(img)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.14465111  0.09083702  0.41782254 ...  2.7458491   1.6808972\n",
            " -0.00417358]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for filename in os.listdir('food_512'):\n",
        "    name = filename.replace(\".jpg\",\"\")\n",
        "    if(name != \"02461\"):\n",
        "        continue\n",
        "\n",
        "    img = Image.open('food_512/' + filename)\n",
        "    img = np.array(img)*1.0/255\n",
        "    feature = model.predict(img[None])[0]\n",
        "    print(feature)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "8000\n",
            "8100\n",
            "8200\n",
            "8300\n",
            "8400\n",
            "8500\n",
            "8600\n",
            "8700\n",
            "8800\n",
            "8900\n",
            "9000\n",
            "9100\n",
            "9200\n",
            "9300\n",
            "9400\n",
            "9500\n",
            "9600\n",
            "9700\n",
            "9800\n",
            "9900\n",
            "10000\n"
          ]
        }
      ],
      "source": [
        "# dictionary with all the image names and their features\n",
        "features = {}\n",
        "\n",
        "# convert every image into features\n",
        "line_id = 0\n",
        "for filename in os.listdir('food_512'):\n",
        "    line_id += 1\n",
        "    img = Image.open('food_512/' + filename)\n",
        "    img = np.array(img)*1.0/255\n",
        "    feature = model.predict(img[None])[0]\n",
        "    features[filename.replace(\".jpg\",\"\")] = feature\n",
        "    if line_id % 100 == 0:\n",
        "        print(line_id)\n",
        "    # break\n",
        "\n",
        "# save the features dictionary to a file using pickle\n",
        "with open('features_xl.pickle', 'wb') as handle:\n",
        "    pickle.dump(features, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.14465111  0.09083702  0.41782254 ...  2.7458491   1.6808972\n",
            " -0.00417358]\n"
          ]
        }
      ],
      "source": [
        "output_shape = 1280\n",
        "features = {}\n",
        "# load the features dictionary from the file\n",
        "with open('features_xl.pickle', 'rb') as handle:\n",
        "    features = pickle.load(handle)\n",
        "print(features['02461'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n",
            "1280\n"
          ]
        }
      ],
      "source": [
        "print(len(features))\n",
        "print(len(features[\"00000\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# each line of train_triplets.txt contains 3 images, separated by a space\n",
        "# the first 2 images are the anchor and positive examples, and the third is the negative example\n",
        "# extract the features of the 3 images and save them in a file\n",
        "# cols = columns=np.array(['x' + str(i) for i in np.arange(output_shape*2)+1])\n",
        "# df_features = pd.DataFrame(columns=cols)\n",
        "# df_labels = pd.DataFrame(columns=['label'])\n",
        "\n",
        "# line_id = 0\n",
        "# with open('train_triplets.txt', 'r') as f:\n",
        "#     # go through the lines\n",
        "#     for line in f:\n",
        "#         line_id += 1\n",
        "#         line = line.replace(\"\\n\", \"\")\n",
        "#         anchor = features[line.split(' ')[0]]\n",
        "#         positive = features[line.split(' ')[1]]\n",
        "#         negative = features[line.split(' ')[2]]\n",
        "#         if random.random() < 0.5:\n",
        "#             row = np.concatenate((positive-anchor, negative-anchor))\n",
        "#             df_labels = df_labels.append(pd.DataFrame(np.array([[1]]), columns=['label']))\n",
        "#         else:\n",
        "#             row = np.concatenate((negative-anchor, positive-anchor))\n",
        "#             df_labels = df_labels.append(pd.DataFrame(np.array([[0]]), columns=['label']))\n",
        "#         # add the new row to the dataframe\n",
        "#         df_features = df_features.append(pd.DataFrame(row.reshape(1, -1), columns=cols))\n",
        "#         if line_id % 5000 == 0:\n",
        "#             print(line_id)\n",
        "#             # break\n",
        "    \n",
        "# print(df_features.shape)\n",
        "# print(df_labels.shape)\n",
        "# df_features.to_csv('train_features.csv',index=False, float_format='%.3f')\n",
        "# df_labels.to_csv('train_labels.csv',index=False)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "l05c01_dogs_vs_cats_without_augmentation.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
